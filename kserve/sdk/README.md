# KServe Python SDK for Model Serving (Not started yet)

- Sung-Soo Kim
- Updated: 14 July, 2022.

* Related Article: [KServe setup and testing](https://github.com/traindb-project/traindb-ml/tree/main/kserve)
	* PyTorch 모델 적용

### References

* [KServe Python SDK](https://kserve.github.io/website/master/sdk_docs/sdk_doc/)
* [Kubeflow Fairing E2E MNIST Case: Building, Training and Serving](https://notebook.community/kubeflow/fairing/examples/mnist/mnist_e2e_on_prem)
	* [Run notebook](https://deepnote.com/workspace/personal-workspace-ab76-d3c1d920-c178-43ec-9793-5be9e81befc3/project/fairing-ee1007f1-7bfd-40ab-8c64-6858b2f11ec4/%2Fexamples%2Fmnist%2Fmnist_e2e_on_prem.ipynb) 	

---

This page describes the method for ML model serving using Python SDK.

KServe's python server libraries implement a standardized library that is extended by model serving frameworks such as Scikit Learn, XGBoost and PyTorch. 

## Summary

I summarize these procedures for serving models using KServe Python SDK as the following.

0. Install Required Dependencies
1. KServe Python Server Setting/Run
2. Inference Service Invocation using KServe's Python Client SDK. 


   
   
   

   
    	


